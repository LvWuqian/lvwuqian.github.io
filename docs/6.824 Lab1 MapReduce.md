# 6.824 Lab1: MapReduce

[任务描述](http://nil.csail.mit.edu/6.824/2020/labs/lab-mr.html)

### My Job

实现分为几步：

1.创建master加载Map任务

2.创建多个worker连接master获取Map任务

3.Map任务完成，master加载Reduce任务

4.worker连接master获取Reduce任务



#### 1.创建master加载Map任务

首先需要定义数据结构

```go
type Master struct {   // Master包含的属性
	Input       []string // 输入待处理文件名
	Tasks       chan *Task // Task的Channel，用于存储任务并释放给Worker
	TaskInfos   map[int]*TaskInfo // 各Task的当前处理信息
	MasterState State // 当前Master处于的状态
	NReduce     int   // 外部给定的Reduce数
	Count       int   // 用于计数任务处理情况
}

type Task struct { // 任务结构体
	TaskId    int // 任务id
	TaskState State // 任务当前状态
	NReduce   int // 外部给定的Reduce数
	Input     string // 当前任务的处理文件
	Output    []string // 输出文件名
}

type TaskInfo struct { // 任务信息
	TaskStatus Status // 任务运行状态
	TaskLink   *Task // 任务Reference
}

type State int // State枚举

const (
	Map State = iota
	Reduce
	Block
	End
)

type Status int // Status枚举

const (
	New Status = iota
	Running
	Completed
)

```

在Master启动时创建Master对象

```go
func MakeMaster(files []string, nReduce int) *Master {
	var chanSize int // Channel的大小，取输入文件和Reduce数较大的一个
	if len(files) > nReduce {
		chanSize = len(files)
	} else {
		chanSize = nReduce
	}
	m := Master{
		Input:       files,
		Tasks:       make(chan *Task, chanSize),
		TaskInfos:   make(map[int]*TaskInfo),
		MasterState: Map,
		NReduce:     nReduce,
		Count:       0,
	}

	// 初始化任务到channel
	for id, file := range files {
		task := &Task{
			TaskId:    id,
			TaskState: Map,
			NReduce:   nReduce,
			Input:     file,
			Output:    make([]string, 0),
		}
		m.Tasks <- task
		taskInfo := &TaskInfo{
			TaskStatus: New,
			TaskLink:   task,
		}
		m.TaskInfos[task.TaskId] = taskInfo
		m.Count += 1
	}

	m.server()
	return &m
}
```

#### 2.创建多个worker连接master获取Map任务

首先，需要在调用的主函数中让Worker在启动后循环执行任务

```go
func Worker(mapf func(string, string) []KeyValue, reducef func(string, []string) string) {
	for {
		task := GetTask() // 使用RPC调用从Master获取Task
		if task.TaskState == Map { // 根据Task的类型执行相应的任务
			Mapper(&task, mapf)
		} else if task.TaskState == Reduce {
			Reducer(&task, reducef)
		} else if task.TaskState == Block {
			time.Sleep(time.Duration(1) * time.Second) // 暂停1秒
		} else {
			return
		}
	}
}
```

GetTask()是使用RPC调用从Master处获得Task

```go
func GetTask() Task {
	args := ExampleArgs{}
	reply := Task{}
	isSuccess := call("Master.SendTask", &args, &reply)
	if !isSuccess {
		fmt.Println("SendTask failed")
	}
	return reply
}

func (m *Master) SendTask(args *ExampleArgs, reply *Task) error {
	// 后续会考虑一下锁
	if len(m.Tasks) > 0 {
		*reply = *<-m.Tasks
		m.TaskInfos[reply.TaskId].TaskStatus = Running
	} else if m.MasterState == Block {
		reply = &Task{TaskState: Block}
	} else {
		reply = &Task{TaskState: End}
	}

	return nil
}
```

在获取到Map任务之后，会执行Map任务，调用`Mapper()`函数

```go
func Mapper(task *Task, mapf func(string, string) []KeyValue) {
	file, err := os.Open(task.Input) // 打开文件
	if err != nil {
		fmt.Println(task)
		log.Fatalf("cannot open %v in mapper", task.Input)
	}
	content, err := ioutil.ReadAll(file)
	if err != nil {
		log.Fatalf("cannot read %v in mapper", task.Input)
	}
	file.Close()
	kva := mapf(task.Input, string(content))

	output := make([][]KeyValue, task.NReduce)
	for _, kv := range kva { // 根据任务要求按Key值把结果存入不同的中间文件
		index := ihash(kv.Key) % task.NReduce
		output[index] = append(output[index], kv)
	}
	for i := 0; i < task.NReduce; i++ {
		filename := "mr-json-" + strconv.Itoa(i) + ".json"
		var filePtr *os.File
		if !checkFileIsExist(filename) {
			filePtr, err = os.Create(filename)
			if err != nil {
				fmt.Println("Create file failed", err.Error())
				continue
			}
		} else {
			filePtr, err = os.OpenFile(filename, os.O_APPEND|os.O_WRONLY, os.ModeAppend)
			if err != nil {
				fmt.Println("Open file failed", err.Error())
				continue
			}
		}
		enc := json.NewEncoder(filePtr)
		for _, kv := range output[i] {
			err := enc.Encode(&kv)
			if err != nil {
				fmt.Println("Encode kv failed", err.Error())
				continue
			}
		}
		task.Output = append(task.Output, filename) // 把暂存文件放入Output属性
		filePtr.Close()
	}
	TaskComplete(task) // 告知Master任务完成
}
```

#### 3.Map任务完成，master加载Reduce任务

需要告知Master当前Task已完成，Master在所有Map任务完成后会加载Reduce任务

```go
func TaskComplete(task *Task) {
	reply := ExampleReply{}
	isSuccess := call("Master.FinishTask", task, &reply)
	if !isSuccess {
		fmt.Println("FinishTask failed")
	}
}

func (m *Master) FinishTask(task *Task, reply *ExampleReply) error {
	// 后续考虑分布式超时丢弃
	m.TaskInfos[task.TaskId].TaskStatus = Completed
	m.Count -= 1
	if m.MasterState == Map {
		if m.Count == 0 {
			m.MasterState = Reduce
			// 添加Reduce任务到Channel
			base := len(m.TaskInfos)
			for id, file := range task.Output {
				task := &Task{
					TaskId:    id + base,
					TaskState: Reduce,
					NReduce:   task.NReduce,
					Input:     file,
					Output:    make([]string, 0),
				}
				m.Tasks <- task
				taskInfo := &TaskInfo{
					TaskStatus: New,
					TaskLink:   task,
				}
				m.TaskInfos[task.TaskId] = taskInfo
				m.Count += 1
			}
		}
	} else {
		if m.Count == 0 {
			m.MasterState = End
		}
	}

	return nil
}
```

#### 4.worker连接master获取Reduce任务

Worker通过`Reducer()`函数处理Reduce任务

```go
func Reducer(task *Task, reducef func(string, []string) string) {
	intermediate := []KeyValue{}
	filePtr, err := os.Open(task.Input)
	if err != nil {
		fmt.Println("Decode kv failed", err.Error())
	}
	dec := json.NewDecoder(filePtr)
	for {
		var kv KeyValue
		if err := dec.Decode(&kv); err != nil {
			break
		}
		intermediate = append(intermediate, kv)
	}
	filePtr.Close()

	sort.Sort(ByKey(intermediate))

	oname := "mr-out-" + strconv.Itoa(task.TaskId)
	ofile, _ := os.Create(oname)

	i := 0
	for i < len(intermediate) {
		j := i + 1
		for j < len(intermediate) && intermediate[j].Key == intermediate[i].Key {
			j++
		}
		values := []string{}
		for k := i; k < j; k++ {
			values = append(values, intermediate[k].Value)
		}
		output := reducef(intermediate[i].Key, values)

		// this is the correct format for each line of Reduce output.
		fmt.Fprintf(ofile, "%v %v\n", intermediate[i].Key, output)

		i = j
	}
	ofile.Close()

	TaskComplete(task)
}
```

在所有Reduce完成后`m.MasterState = End`

```go
func (m *Master) Done() bool {
	ret := m.MasterState == End
	return ret
}
```

脚本会周期性调用`Done()`函数使得程序终止



目前上述代码能通过脚本前三个测试，因为部分原因没有继续把所有细节完善，后续主要还需要

1.在Master加入锁机制保证并发不会出错

2.加入超时重做机制，给Worker限定时间



### 其他知识点

#### 1.Go Plugin

在给定的任务中给出了一个`-buildmode=pugin`参数，如下所示

```go
go build -buildmode=plugin ../mrapps/wc.go
```

这是以插件形式对`wc.go`进行编译，得到`wc.so`



> ```sh
> -buildmode=plugin
> 	Build the listed main packages, plus all packages that they
> 	import, into a Go plugin. Packages not named main are ignored.
> ```
>
> Go提供的plugin包可以实现**热更新**的功能。
>
> Go插件是使用`-buildmode = plugin`标记编译的一个包，用于生成一个共享对象（.so）库文件。 Go包中的导出的函数和变量被公开为ELF符号，可以使用plugin包在运行时查找并绑定ELF符号。

[官方Plugin解释](https://pkg.go.dev/plugin)



#### 2.RPC

[rpc package](https://pkg.go.dev/net/rpc)

[Go官方库RPC开发指南](https://colobu.com/2016/09/18/go-net-rpc-guide/)



#### 3.Mac OS缺少timeout命令

`timeout`是属于linux中的命令，因为`test-mr.sh`中大量使用`timeout`进行测试，Mac OS无法支持

传统方法是采用`brew install coreutils`安装coreutils，并使用其`gtimeout`代替`timeout`，但是尝试了各种方法仍然无法安装coreutils，最后选择了在脚本中加入

```sh
timeout () { perl -e 'alarm shift; exec @ARGV' "$@"; }
```

并把涉及`timeout`的命令做了一些修改

```sh
timeout -k 2s 180s ../mrworker ../../mrapps/wc.so & # 原来的命令修改为了下面
timeout 180s ../mrworker ../../mrapps/wc.so & # 修改后的命令
```

